{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Cross-Validation with Symmetric Pair-Input Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    "1. Implement the modified leave-one-out cross-validation scheme that is described in the lecture notes.\n",
    "\n",
    "2. Estimate and report the generalisation performance of the K-nearest neighbor classifier in predicting the functional similarity of proteins. Use both the unmodified and the modified leave-one-out cross-validation.\n",
    "\n",
    "3. Discuss your results. In particular, answer the following questions:\n",
    " - Why do the two cross-validation schemes produce notably different estimates?\n",
    " - For which types of pairs (A, B, or C) are these schemes appropriate and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cindex(true_labels, predictions):\n",
    "    n = 0\n",
    "    h_sum = 0\n",
    "\n",
    "    for i in range (len(true_labels)):\n",
    "        t = true_labels[i]\n",
    "        p = predictions[i]\n",
    "        j= i+1\n",
    "        for j in range(len(true_labels)):\n",
    "            nt = true_labels[j]\n",
    "            np = predictions[j]\n",
    "            if t != nt:\n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt):\n",
    "                    h_sum = h_sum + 1\n",
    "                elif p == np:\n",
    "                    h_sum = h_sum + 0.5\n",
    "    cindx = h_sum/n\n",
    "    return cindx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index using unmodified leave-one-out cross-validation: 0.7617702448210922\n",
      "C-index performance using modified leave-one-out cross-validation: 0.6313559322033898\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load datasets\n",
    "pairs = np.genfromtxt('pairs.data', delimiter=',', dtype=('U50', 'U50'))\n",
    "features = np.genfromtxt('features.data', delimiter=',')\n",
    "labels = np.genfromtxt('labels.data', delimiter=',')\n",
    "\n",
    "# prediction lists to calculate c-index performance\n",
    "predictions=[]\n",
    "predictions2=[]\n",
    "\n",
    "# Loop for each pair\n",
    "for x in range(len(pairs)):  \n",
    "    \n",
    "    # test set\n",
    "    test_pair = pairs[x, :]\n",
    "    \n",
    "    # Pairs member 1\n",
    "    test_pair_1 = test_pair[0]\n",
    "    \n",
    "    # Pairs member 2\n",
    "    test_pair_2 = test_pair[1]\n",
    "    \n",
    "    # delete rows used for testing to create trainset (Unmodified leave-one-out cross-validation)\n",
    "    pairs_trainset = np.delete(pairs, (x), axis=0)\n",
    "    features_trainset = np.delete(features, (x), axis=0)\n",
    "    labels_trainset = np.delete(labels, (x), axis=0)\n",
    "      \n",
    "    # KNN prediction with k=1 and euclidean distance\n",
    "    neigh1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh1.fit(features_trainset, labels_trainset)\n",
    "    \n",
    "    prediction = neigh1.predict([features[x]])\n",
    "    predictions.append(prediction)\n",
    "    \n",
    " \n",
    "    # lists for modified dataset\n",
    "    modified_pairs = []\n",
    "    modified_del_index = []\n",
    "    \n",
    "    #loop through training set pairs\n",
    "    for n in range(len(pairs_trainset)):\n",
    "        test_pair2 = pairs_trainset[n]\n",
    "        \n",
    "        # Filter pairs in training set containing test pair instances\n",
    "        if test_pair2[0] != test_pair_1 and test_pair2[0] != test_pair_1 and test_pair2[1] != test_pair_2 and test_pair2[1] != test_pair_2:\n",
    "            modified_pairs.append(test_pair2)\n",
    "        else:\n",
    "            modified_del_index.append(n)\n",
    "    \n",
    "    # Deleting rows from trainsets containing test pair instances\n",
    "    features_modified = np.delete(features_trainset, (modified_del_index), axis=0)\n",
    "    labels_modified = np.delete(labels_trainset, (modified_del_index), axis=0)\n",
    "    \n",
    "    # KNN prediction modified\n",
    "    neigh2 = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh2.fit(features_modified, labels_modified)\n",
    "    \n",
    "    prediction2 = neigh2.predict([features[x]])\n",
    "    predictions2.append(prediction2)\n",
    "    \n",
    "    \n",
    "# Unmodified c-index calculation\n",
    "\n",
    "C_index =cindex(labels, predictions)\n",
    "print(\"C-index using unmodified leave-one-out cross-validation:\", C_index)\n",
    "\n",
    "\n",
    "# Modified c-index calculation\n",
    "C_index2 = cindex(labels, predictions2)\n",
    "print(\"C-index performance using modified leave-one-out cross-validation:\", C_index2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) \n",
    "The two cross-validation schemes produce notably different estimates because the data is symmetric pair-input data. This means pairs that have same members have depencies. This way is propably information leak beteen the test set and training set. Using modified leave-one-out corss-validation this issue fixed by removing the shared members from  the training set.\n",
    "This is also why the unmodified scheme gives \"better\" perfomance, but it's more optimisitic than the more realistic of modified result.\n",
    "\n",
    "2)\n",
    "Modified leave-one-out cross-validation works better for case C because of no unknown members instance are present in known instances, so the cross-validation is faster because there are less rows in training set than in unmodified leave-one-out crossvalidation scheme. \n",
    "\n",
    "Unmodified leave-one-out cross-validation works better for case A because both members of unknown instance are present in   n instances, so there are dependencies between training and test sets, which leads to better generalisation performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
