{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 |  Application of Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of the metal ion content from multi-parameter data <br>\n",
    "- Use K-Nearest Neighbor Regression with euclidean distance to predict total metal concentration (c_total), concentration of Cadmium (Cd) and concentration of Lead (Pb), for each sample using number of neighbors k = 3.<br> <br>\n",
    "\n",
    "    - You may use Nearest Neighbor Regression from https://scikit-learn.org/stable/modules/neighbors.html\n",
    "    - The data should be standarized using z-score.\n",
    "    - Implement your own Leave-One-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb). \n",
    "    - Implement your own Leave-Replicas-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell import all libraries you need. For example: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell read the file water_data.csv\n",
    "#Print the dataset dimesions (i.e. number of rows and columns)\n",
    "df = pd.read_csv(\"Water_data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To show understanding of the data, answer the following questions:\n",
    "- How many different mixtures of Cadmium (Cd) and Lead (Pb) were measured? <br>\n",
    "- How many total concentrations (c_total) were measured? <br>\n",
    "- For each c_total, how many times the measurement was repeated? To answer this question <br>\n",
    "  create a table or make a bar plot of c_total / number of repetitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Different unique mixtures: 67\n",
      "Amount of unique total concentrations: 12\n",
      "200     24\n",
      "100     24\n",
      "70      24\n",
      "50      24\n",
      "500     18\n",
      "1000    18\n",
      "2000    18\n",
      "5000    18\n",
      "35      18\n",
      "20      18\n",
      "14      18\n",
      "0        3\n",
      "Name: c_total, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#In this cell write the code to answer the previous questions and print the answers.\n",
    "# Calculating the amount of different mixtures of Cd and Pb \n",
    "df_mixtures = df.groupby(['Cd','Pb']).size().reset_index().shape\n",
    "print ('Amount Different unique mixtures:' , df_mixtures[0])\n",
    "\n",
    "# total concentrations\n",
    "df_c_total = df['c_total'].value_counts()\n",
    "print ('Amount of unique total concentrations:', df_c_total.shape[0])\n",
    "\n",
    "print (df_c_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c_total      Cd      Pb      Mod1      Mod2      Mod3\n",
      "0       2000   800.0  1200.0  0.166505 -0.508756 -1.499041\n",
      "1         35    14.0    21.0 -0.892616 -0.701641  0.685861\n",
      "2         35    14.0    21.0 -0.852896 -0.701806  1.065760\n",
      "3         35    35.0     0.0 -0.040629 -0.643767  0.584863\n",
      "4        100    20.0    80.0 -0.520568 -0.276268 -0.058789\n",
      "5       1000  1000.0     0.0  0.464578  0.213261  0.549090\n",
      "6         14     5.6     8.4 -0.994542 -0.715696 -0.030300\n",
      "7         50    40.0    10.0  0.657312 -0.143324  0.694356\n",
      "8        500   100.0   400.0  1.122030 -0.446665 -1.424027\n",
      "9        100   100.0     0.0  1.651645  2.122186  0.792002\n",
      "10        14    11.2     2.8 -0.935218 -0.713381  0.255056\n",
      "11      1000   400.0   600.0  0.640710 -0.452701 -1.393331\n",
      "12        50     0.0    50.0 -0.933817 -0.698003 -0.089966\n",
      "13        14    11.2     2.8 -0.929043 -0.712637  0.937766\n",
      "14      1000   600.0   400.0  0.597287 -0.550673 -1.407286\n",
      "15        70     0.0    70.0 -0.916894 -0.695688  0.310408\n",
      "16      5000     0.0  5000.0 -0.926211 -0.267835 -1.514091\n",
      "17        20    12.0     8.0 -1.011385 -0.711397  0.316581\n",
      "18        70    56.0    14.0  1.380433  2.175513  1.293441\n",
      "19       500   200.0   300.0  1.109960 -0.280981 -1.131271\n",
      "20        70     0.0    70.0 -0.922519 -0.705692  0.222319\n",
      "21        50     0.0    50.0 -0.956934 -0.697838  0.377690\n",
      "22       500   300.0   200.0  1.091106 -0.349685 -1.187271\n",
      "23       100   100.0     0.0  1.709038  2.525153  0.819496\n",
      "24      2000   400.0  1600.0  0.294221 -0.479323 -1.531679\n",
      "25       200   160.0    40.0  1.798865  1.861506  1.198814\n",
      "26         0     0.0     0.0 -0.990539 -0.714125  0.020788\n",
      "27      5000  3000.0  2000.0 -0.893437 -0.634590 -1.579398\n",
      "28      1000     0.0  1000.0 -0.591091 -0.554476 -1.498710\n",
      "29        50    50.0     0.0  1.138011  1.206375  0.640331\n",
      "..       ...     ...     ...       ...       ...       ...\n",
      "195      100    20.0    80.0 -0.499873 -0.155395 -0.245221\n",
      "196       14     8.4     5.6 -0.903684 -0.713050  1.476272\n",
      "197       14     8.4     5.6 -0.910860 -0.714290  0.389355\n",
      "198       70    28.0    42.0 -0.224477 -0.513220  0.290298\n",
      "199       70    56.0    14.0  1.495749  2.377657  1.457141\n",
      "200       70    56.0    14.0  1.557985  2.081344  1.226540\n",
      "201      500   500.0     0.0  0.919688  0.468484  0.456720\n",
      "202       50    50.0     0.0  1.065307  1.219024  0.471288\n",
      "203      100    80.0    20.0  1.717625  2.391878  0.709505\n",
      "204     1000  1000.0     0.0  0.365734  0.380268  0.492941\n",
      "205     5000  4000.0  1000.0 -0.874613 -0.584157 -1.515186\n",
      "206     5000     0.0  5000.0 -0.917855 -0.352744 -1.512365\n",
      "207       70    28.0    42.0 -0.088475 -0.406815  0.449900\n",
      "208      200     0.0   200.0 -0.773097 -0.058746 -0.672691\n",
      "209       70    70.0     0.0  1.910999  2.569633  1.096406\n",
      "210      200   120.0    80.0  1.661032  1.419598 -0.163022\n",
      "211      100    40.0    60.0  0.604893  0.666991 -0.240227\n",
      "212     1000   200.0   800.0  0.681150 -0.500157 -1.486016\n",
      "213     5000  2000.0  3000.0 -0.778261 -0.517519 -1.544986\n",
      "214     1000   800.0   200.0  0.512364 -0.395571 -0.998267\n",
      "215       70    42.0    28.0  0.636417  0.911384  0.607959\n",
      "216      200   120.0    80.0  1.798275  1.138580 -0.043574\n",
      "217      200    80.0   120.0  1.652686  0.885093 -0.262975\n",
      "218      500   200.0   300.0  1.272472 -0.294292 -1.189378\n",
      "219       50    10.0    40.0 -0.769134 -0.663279  0.683405\n",
      "220     2000     0.0  2000.0 -0.645171 -0.495941 -1.530484\n",
      "221     5000  4000.0  1000.0 -0.874613 -0.677499 -1.491442\n",
      "222       50    30.0    20.0 -0.603170 -0.537114  1.873760\n",
      "223       50     0.0    50.0 -0.926602 -0.699822  0.351225\n",
      "224     2000   800.0  1200.0  0.174902 -0.521240 -1.492006\n",
      "\n",
      "[225 rows x 6 columns]\n",
      "       Mod1      Mod2      Mod3\n",
      "0  0.166505 -0.508756 -1.499041\n",
      "1 -0.892616 -0.701641  0.685861\n",
      "2 -0.852896 -0.701806  1.065760\n",
      "3 -0.040629 -0.643767  0.584863\n",
      "4 -0.520568 -0.276268 -0.058789\n"
     ]
    }
   ],
   "source": [
    "#Standardize the dataset features by removing the mean and scaling to unit variance. \n",
    "#In other words, use z-score to scale the dataset features (Mod1, Mod2, Mod3)\n",
    "df_f = df.drop(df.columns[[0,1,2]], axis=1)\n",
    "df_z = df_f.apply(zscore)\n",
    "df_t = df.drop(df.columns[[3,4,5]], axis=1)\n",
    "df = pd.concat([df_t, df_z], axis=1)\n",
    "print(df)\n",
    "#Print the 5 first samples (i.e. rows) of the scaled dataset\n",
    "print (df_z[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-index code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cindex(true_labels, predictions):\n",
    "    \"\"\"Returns C-index between true labels and predicted labels\"\"\"\n",
    "    n = 0\n",
    "    h_sum = 0\n",
    "\n",
    "    for i in range (1, len(true_labels)):\n",
    "        t = true_labels[i]\n",
    "        p = predictions[i]\n",
    "        j = i + 1\n",
    "        for j in range(j, len(true_labels)):\n",
    "            nt = true_labels[j]\n",
    "            np = predictions[j]\n",
    "            if t != nt:\n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt):\n",
    "                    h_sum = h_sum + 1\n",
    "                elif p == np:\n",
    "                    h_sum = h_sum + 0.5\n",
    "    cindx = h_sum/n    \n",
    "    return cindx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#test cindex function with following values\n",
    "true_labels = [-1, 1, 1, -1, 1]\n",
    "predictions = [0.60, 0.80, 0.75, 0.75, 0.70]\n",
    "cindx = cindex(true_labels, predictions)\n",
    "print(cindx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include here all the functions that you need to run in the data analysis part.\n",
    "\n",
    "# Input values\n",
    "x = df.drop(columns=['c_total','Cd','Pb'])\n",
    "\n",
    "#Target values\n",
    "c_total = df['c_total'].values\n",
    "Cd = df['Cd'].values\n",
    "Pb = df['Pb'].values\n",
    "#c_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Leave-One-Out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-one-out Cross validation c_total\n",
      "C-index = 0.9135875520490905\n",
      "Leave-one-out Cross validation Cd\n",
      "C-index = 0.8991276129467296\n",
      "Leave-one-out Cross validation Pb\n",
      "C-index = 0.8734246575342466\n"
     ]
    }
   ],
   "source": [
    "#In this cell run your code for leave-One-Out cross-validation and print the corresponding results.\n",
    "\n",
    "\n",
    "# Leave-one-out Cross validation c_total\n",
    "print('Leave-one-out Cross validation c_total')\n",
    "neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "cv_predictions = cross_val_predict(neigh, x, c_total, cv=LeaveOneOut())\n",
    "print('C-index =', cindex(c_total,cv_predictions))\n",
    "\n",
    "print('Leave-one-out Cross validation Cd')\n",
    "cv_predictions = cross_val_predict(neigh, x, Cd, cv=LeaveOneOut())\n",
    "print('C-index =', cindex(Cd,cv_predictions))\n",
    "\n",
    "print('Leave-one-out Cross validation Pb')\n",
    "cv_predictions = cross_val_predict(neigh, x, Pb, cv=LeaveOneOut())\n",
    "print('C-index =', cindex(Pb,cv_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_total C-index: 0.9135875520490905\n",
      "Cd C-index: 0.8991276129467296\n",
      "Pb C-index: 0.8734246575342466\n"
     ]
    }
   ],
   "source": [
    "df_a = df.values\n",
    "pred_c_total= []\n",
    "pred_Cd= []\n",
    "pred_Pb= []\n",
    "true_labels = df_a[:,[0,1,2]]\n",
    "true_c_total = []\n",
    "\n",
    "\n",
    "for x in range(len(df_a)):\n",
    "        #Select row for testing\n",
    "        testset = df_a[x, [3,4,5]]\n",
    "        \n",
    "        #Delete row that is used for testing to create training set ( Leave-one-out cross-validation)\n",
    "        trainset = np.delete(df_a, (x), axis=0)\n",
    "        \n",
    "        knn = KNeighborsRegressor(n_neighbors=3)\n",
    "        knn.fit(trainset[:,[3,4,5]], trainset[:,[0,1,2]])\n",
    "        #Prediction on testset row\n",
    "        prediction = knn.predict([testset])\n",
    "        \n",
    "        # Add predicitons to separate list by output\n",
    "        pred_c_total.append(prediction[0][0])\n",
    "        pred_Cd.append(prediction[0][1])\n",
    "        pred_Pb.append(prediction[0][2])\n",
    "        \n",
    "\n",
    "#Calculate each C-index\n",
    "C_total_cindex = cindex(true_labels[:,0], pred_c_total)\n",
    "Cd_cindex = cindex(true_labels[:,1], pred_Cd)\n",
    "Pb_cindex = cindex(true_labels[:,2], pred_Pb)\n",
    "\n",
    "print('C_total C-index:', C_total_cindex)\n",
    "print('Cd C-index:', Cd_cindex)\n",
    "print('Pb C-index:', Pb_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Leave-Replicas-Out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replicas =df.drop_duplicates(['Cd','Pb'],keep= 'first')\n",
    "mixture_cd = df_replicas['Cd'].values\n",
    "mixture_pb = df_replicas['Pb'].values\n",
    "c_total = df['c_total'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_total C-index: 0.8251889168765743\n",
      "Cd C-index: 0.7472073822243808\n",
      "Pb C-index: 0.7665208940719145\n"
     ]
    }
   ],
   "source": [
    "#In this cell run your script for leave-Replicas-Out cross-validation and print the corresponding results.\n",
    "\n",
    "\n",
    "true_labels = []\n",
    "true_c_total = []\n",
    "c_total_cindex_array = []\n",
    "true_labels_c = []\n",
    "Cd_cindex = []\n",
    "Pb_cindex = []\n",
    "\n",
    "for m in range(len(df_replicas)):\n",
    "    pred_c_total= []\n",
    "    pred_Cd= []\n",
    "    pred_Pb= []\n",
    "    \n",
    "    # get replicas row indices\n",
    "    test_index = np.where((df_a[:,1] == mixture_cd[m]) & (df_a[:,2] == mixture_pb[m]))\n",
    "\n",
    "    # create test set using the replicas indices\n",
    "    testset = df_a[test_index]\n",
    "     #get c_total true value for each mixture\n",
    "    true_index = test_index[0][0]\n",
    "    true_labels_c.append(c_total[true_index])\n",
    "    \n",
    "    # create training set by deleting the test test from the data (Leave-Replicas-Out cross-validation)\n",
    "    trainset = np.delete(df_a, (test_index), axis=0)\n",
    "    trainset_f = trainset[:,[3,4,5]]\n",
    "    trainset_t = trainset[:,[0,1,2]]\n",
    "    \n",
    "    # KNN prediction for each testset row\n",
    "    for x in range(len(testset)):\n",
    "        \n",
    "        testset_row = testset[x, [3,4,5]]\n",
    "        \n",
    "        knn = KNeighborsRegressor(n_neighbors=3)\n",
    "        knn.fit(trainset_f, trainset_t)\n",
    "        \n",
    "        prediction = knn.predict([testset_row])\n",
    "        \n",
    "        pred_c_total.append(prediction[0][0])\n",
    "        pred_Cd.append(prediction[0][1])\n",
    "        pred_Pb.append(prediction[0][2])\n",
    "        \n",
    " \n",
    "    # Compute averages of replica set\n",
    "    C_total_average = np.average(pred_c_total)\n",
    "    Cd_average = np.average(pred_Cd)\n",
    "    Pb_average = np.average(pred_Pb)\n",
    "    \n",
    "    # Add averages to list\n",
    "    c_total_cindex_array.append(C_total_average)\n",
    "    Cd_cindex.append(Cd_average)\n",
    "    Pb_cindex.append(Pb_average)\n",
    "\n",
    "#Calculate each C-index \n",
    "C_total_cindex = cindex(true_labels_c, c_total_cindex_array)\n",
    "Cd_cindex = cindex(mixture_cd, Cd_cindex)\n",
    "Pb_cindex = cindex(mixture_pb, Pb_cindex)\n",
    "\n",
    "print('C_total C-index:', C_total_cindex)\n",
    "print('Cd C-index:', Cd_cindex)\n",
    "print('Pb C-index:', Pb_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results\n",
    "#### Answer the following questions based on the results obtained\n",
    "- Which cross-validation approach had more optimistic results?\n",
    "- Which cross-validation generalize better on unseen data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#In this cell write your answers to the questions about Interpretation of Results.\n",
    "\n",
    "Leave-One-Out cross-validation gives more optimistic results.\n",
    "Leave-Replicas-Out cross-validation method it better for generalizing on unseen data, because there is no data leakage from the replicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
