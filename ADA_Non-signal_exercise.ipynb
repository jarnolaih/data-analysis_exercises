{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-signal data exercise\n",
    "\n",
    "In this exercise you take on the role of a senior data analyst correcting mistakes made by a junior analyst. Your consulting company has received the MysteryData data set, and your goal is to build a classifier out of it, and evaluate how well the classifer works. You assigned the job to junior trainee Tux the Linux Penguin (who works for food).\n",
    "\n",
    "Tux is very excited to work on the data and has produced very promising results. What Tux does not yet know is that MysteryData is actually just random non-signal data where the features x and the class label y are independent of each other - it is not possible to learn anything meaningful from this data. Tux has never taken any of the UTU data analytics courses and has not noticed this. You should help Tux to correct the analyses, so you do not end up reporting incorrect results to your customers.\n",
    "\n",
    "The analysed problem is a binary classification task. We will follow the convention of using +1 to represent the positive class, and -1 the negative. In all but one task we will use area under ROC curve (AUC) to evaluate how well the classifier predicts. For binary classification tasks AUC and c-index are equivalent, 0.5 means random performance and 1.0 perfect predictions. The \"true\" AUC you would expect to see on a large enough sample of independent test data for any classifier trained on non-signal data is 0.5.\n",
    "\n",
    "Note that amount of samples, features, and class distribution for MysteryData can differ in different parts of the exercise (these are always written in comments above the code generating the data). Also, in one case there will be a data set on which it is possible to learn better than random classifier.\n",
    "\n",
    "Some notes on the codes:\n",
    "- we use predict_proba() instead of predict() when using AUC, because the predicted class probabilities are needed for computing AUC properly (predict() returns only +1/-1 values)\n",
    "- random seeds are fixed to guarantee that re-running the codes gives same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "#The data, trust me, you can't learn anything useful from this\n",
    "def load_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of features\n",
    "    #positives: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X = rand_state.randn(samples, features)\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    y = rand_state.permutation(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: some elementary mistakes\n",
    "\n",
    "## Lesson 1.1: never trust your ----- set performance\n",
    "\n",
    "The first analysis done by Tux contains an obvious elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got area under ROC curve 0.885600\n",
      "Tux: \"I got very high AUC, problem solved!!\"\n"
     ]
    }
   ],
   "source": [
    "#100 samples, 100 features, 50 belong to positive class\n",
    "X, y = load_mystery_data(100, 100, 50, 2)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "learner = KNeighborsClassifier(n_neighbors=2)\n",
    "learner.fit(X, y)\n",
    "#get the estimated probability of belonging to class 1\n",
    "p = learner.predict_proba(X)[:,1]\n",
    "auc = roc_auc_score(y, p)\n",
    "print(\"I got area under ROC curve %f\" % auc)\n",
    "print('Tux: \"I got very high AUC, problem solved!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "Why can't you trust the AUC result of Tux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.1 here\n",
    "\n",
    "There is no tranining and test set split done to the data set. The tested data is included in the training set, which leads to too optmisitic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1.2: trivial baselines\n",
    "\n",
    "The second analysis done by Tux is done a bit better, but analysis of results contains another elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.900000\n",
      "Tux: \"I got 90% classification accuracy, problem solved!!\"\"\n"
     ]
    }
   ],
   "source": [
    "#1000 samples, 100 features, 100 belong to positive class\n",
    "X, y = load_mystery_data(1000, 100, 100, 1)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Instead of AUC I will use classification accuracy!\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Now I use a separate test set!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify=y, random_state=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "p_test = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, p_test)\n",
    "print(\"Classification accuracy: %f\" %accuracy)\n",
    "print('Tux: \"I got 90% classification accuracy, problem solved!!\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "1. Does the high classification accuracy really mean that this is a good predictor?\n",
    "2. Look at the test set predictions in p_test, what has this classifier actually learned?\n",
    "3. What would the results look like if you used AUC instead of classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.2 here\n",
    "\n",
    "1) In this case the high accuracy doesnt necessary mean that it's a good predictor in general, only for this test set.\n",
    "\n",
    "2) It has learned to predict classification for one test set, based on it's 10 nearest neighbors in training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582389552087\n"
     ]
    }
   ],
   "source": [
    "# 3) Results using AUC insted of classification accuracy \n",
    "from sklearn.metrics import roc_auc_score\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, prediction)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: introduction to permutation tests\n",
    "\n",
    "Next, we are using permutation tests to estimate, how likely we are to see AUC values as high as observed, if y is independent of x (non-signal data).\n",
    "\n",
    "The test is implemented as follows:\n",
    "- let AUC_original be the AUC obtained in the original analysis\n",
    "- For 1000 (or preferably more if you have enough CPU time to use) repetitions, shuffle the labels in y, then run the analysis again and compute the AUC value. Store all 1000 AUC values in a list.\n",
    "- Visualization: visualize the permutation distribution by plotting a histogram of the 1000 AUC values. Does AUC_original look like an outlier, or do you often get as good or better results with permuted class labels?\n",
    "- p-value: relative fraction of runs, where obtained AUC $\\geq$ AUC_original\n",
    "- example: AUC with original class labeling is 0.6. In 70 runs out of 1000, we obtain as high as or larger AUC. p-value is then $\\frac{70}{1000} = 0.07$ \n",
    "- result is considered statistically significant, if $p<\\alpha$, where $\\alpha$ a pre-specified significance level (often $\\alpha=0.05$ or $\\alpha=0.01$). Statistical significance does not mean that the results are good, only that the classifier has likely learned something from the data. In the following experiments, use $\\alpha=0.05$.\n",
    "\n",
    "## Lesson 2.1: sample size\n",
    "\n",
    "Tux is now analyzing a small data set with 5-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.700000\n",
      "Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %auc)\n",
    "print('Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.088000\n",
      "Because p-value 0.088000 > 0.05, this means that the results are not statistically significant\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc_list = []\n",
    "\n",
    "p = 0.0\n",
    "k = 1000\n",
    "\n",
    "for c in range(k):\n",
    "\n",
    "    y_permutation = np.random.permutation(y) \n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y_permutation):\n",
    "        X_train = X[train]\n",
    "        y_train = y_permutation[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y_permutation[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    auc = np.mean(cv_aucs)\n",
    "    auc_list.append(auc)\n",
    "    if auc >= 0.7:\n",
    "        p += 1\n",
    "\n",
    "\n",
    "p_value = p / k\n",
    "\n",
    "plt.hist(auc_list, bins='auto')\n",
    "plt.show()\n",
    "\n",
    "print('p-value: %f' %p_value)\n",
    "print('Because p-value %f > 0.05, this means that the results are not statistically significant' %p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2.2: sample size again\n",
    "\n",
    "Let's give poor Tux a better data set that actually has clear difference between the classes and see how things work out. (on this data it is possible to obtain true AUC larger than 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X_pos = rand_state.randn(positives, features)\n",
    "    X_neg = rand_state.randn(samples-positives, features)+0.65\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    I = rand_state.permutation(samples)\n",
    "    X = X[I]\n",
    "    y = y[I]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.875000\n",
      "Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_new_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %cv_auc)\n",
    "print('Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.003000\n",
      "Because p-value 0.003000 < 0.05, this means that the results are statistically significant\n"
     ]
    }
   ],
   "source": [
    "auc_list = []\n",
    "\n",
    "p = 0.0\n",
    "k = 1000\n",
    "\n",
    "for c in range(k):\n",
    "\n",
    "    y_permutation = np.random.permutation(y)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    \n",
    "    for train, test in cv.split(X, y_permutation):\n",
    "        X_train = X[train]\n",
    "        y_train = y_permutation[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y_permutation[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    cv_auc = np.mean(cv_aucs)\n",
    "    auc_list.append(cv_auc)\n",
    "    if cv_auc >= 0.875:\n",
    "        p += 1\n",
    "\n",
    "plt.hist(auc_list, bins='auto')\n",
    "plt.show()\n",
    "\n",
    "p_value = p / k\n",
    "\n",
    "print('p-value: %f' %p_value)\n",
    "print('Because p-value %f < 0.05, this means that the results are statistically significant' %p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: mis-using feature selection\n",
    "\n",
    "Here is a very simple correlation based feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return I[:scount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tux: \"My CV-AUC before feature selection is 0.496000\"\n",
      "Tux: \"My CV-AUC after feature selection is 0.808000, it really works!!\"\n"
     ]
    }
   ],
   "source": [
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC before feature selection is %f\"' %cv_auc)\n",
    "\n",
    "\n",
    "#I'm going to improve my AUC with feature selection!!!\n",
    "I = select(X, y, 5)\n",
    "X_fs = X[:,I]\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X_fs, y):\n",
    "    X_train = X_fs[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X_fs[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC after feature selection is %f, it really works!!\"' %cv_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "\n",
    "It is possible to implement a permutation test for the (incorrect) combination of feature selection and cross-validation Tux has implemented here. Simply run the flawed analysis for 1000 random permutations of y. \n",
    "\n",
    "Use permutation test to show Tux that the feature selection based classification approach is actually not learning anything from the data ($\\alpha=0.05$, provide both visualization of the permutation distribution, as well as the p-value). Running the test may take a while. Analyse what is going on here, why did the results look so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.691000\n",
      "Because p-value 0.691000 > 0.05, this means that the results are not statistically significant\n",
      "Original results look good because the feature selection is done outside the cross-validation, which means the test sets are also used to select features\n"
     ]
    }
   ],
   "source": [
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return X[:,I[:scount]]\n",
    "\n",
    "p = 0.0\n",
    "k = 1000\n",
    "auc_list = []\n",
    "\n",
    "for c in range(k):\n",
    "    y_permutation = np.random.permutation(y)\n",
    "    X_fs = select(X, y_permutation, 5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X_fs, y_permutation):\n",
    "        X_train = X_fs[train]\n",
    "        y_train = y_permutation[train]\n",
    "        X_test = X_fs[test]\n",
    "        y_test = y_permutation[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    cv_auc = np.mean(cv_aucs)\n",
    "    auc_list.append(cv_auc)\n",
    "    if cv_auc >= 0.808:\n",
    "        p += 1\n",
    "\n",
    "plt.hist(auc_list, bins='auto')\n",
    "plt.show()\n",
    "\n",
    "p_value = p / k\n",
    "\n",
    "print('p-value: %f' %p_value)\n",
    "print('Because p-value %f > 0.05, this means that the results are not statistically significant' %p_value)\n",
    "print('Original results look good because the feature selection is done outside the cross-validation, which means the test sets are also used to select features')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
